<div id="top">

<!-- HEADER STYLE: CLASSIC -->
<div align="center">


# BUILDING-A-TRANSFORMER-FROM-SCRATCH

<em>Unleash Creativity with Next-Gen Language Power</em>

<!-- BADGES -->
<img src="https://img.shields.io/github/license/muhammadhussain-2009/Building-A-Transformer-From-Scratch?style=flat&logo=opensourceinitiative&logoColor=white&color=0080ff" alt="license">
<img src="https://img.shields.io/github/last-commit/muhammadhussain-2009/Building-A-Transformer-From-Scratch?style=flat&logo=git&logoColor=white&color=0080ff" alt="last-commit">
<img src="https://img.shields.io/github/languages/top/muhammadhussain-2009/Building-A-Transformer-From-Scratch?style=flat&color=0080ff" alt="repo-top-language">
<img src="https://img.shields.io/github/languages/count/muhammadhussain-2009/Building-A-Transformer-From-Scratch?style=flat&color=0080ff" alt="repo-language-count">

<em>Built with the tools and technologies:Python, Jupyter Notebook, Tensorflow, Pytorch, </em>

<img src="https://img.shields.io/badge/Markdown-000000.svg?style=flat&logo=Markdown&logoColor=white" alt="Markdown">

</div>
<br>

---

## Table of Contents

- [Overview](#overview)
- [Getting Started](#getting-started)
    - [Prerequisites](#prerequisites)
    - [Installation](#installation)
    - [Usage](#usage)
    - [Testing](#testing)
- [Features](#features)
- [Project Structure](#project-structure)
    - [Project Index](#project-index)
- [Contributing](#contributing)
- [License](#license)

---

## Overview

Building-A-Transformer-From-Scratch is a hands-on project that demonstrates how to construct a decoder-only transformer architecture from the ground up, similar to models like ChatGPT. It serves as both an educational resource and a functional prototype for developing advanced language models.

**Why Building-A-Transformer-From-Scratch?**

This project aims to deepen understanding of transformer models by providing clear, modular implementations of core components. The core features include:

- **üß©** **Educational Clarity:** Step-by-step implementation of transformer architecture to facilitate learning.
- **üöÄ** **Prototype Development:** A practical foundation for building custom autoregressive language models.
- **üîß** **Modular Design:** Easily extend or modify components to suit specific research or application needs.
- **üìö** **Sequence Modeling Focus:** Designed for tasks like text generation and language understanding.
- **üéØ** **Open-Source Flexibility:** Clear licensing and accessible code to foster collaboration and innovation.

---

## Features

|      | Component       | Details                                                                                     |
| :--- | :-------------- | :------------------------------------------------------------------------------------------ |
| ‚öôÔ∏è  | **Architecture**  | <ul><li>Implementing Transformer architecture from scratch</li><li>Includes Multi-Head Attention, Positional Encoding, Feedforward layers</li><li>Modular design separating core components</li></ul> |
| üî© | **Code Quality**  | <ul><li>Clear, well-commented Python code</li><li>Consistent function and variable naming</li><li>Uses type hints for better readability</li></ul> |
| üìÑ | **Documentation** | <ul><li>Basic README with project overview</li><li>In-code docstrings for classes and functions</li><li>Jupyter notebooks demonstrating training process</li></ul> |
| üîå | **Integrations**  | <ul><li>Uses `markdown` and `jupyternotebook` for documentation and tutorials</li><li>License file included for open-source licensing</li></ul> |
| üß© | **Modularity**    | <ul><li>Separate modules for Attention, Positional Encoding, and Model</li><li>Reusable components for experimentation</li></ul> |
| üß™ | **Testing**       | <ul><li>Limited unit tests for core functions</li><li>Test cases verifying attention calculations and data shapes</li></ul> |
| ‚ö°Ô∏è  | **Performance**   | <ul><li>Vectorized operations with NumPy/PyTorch for efficiency</li><li>Batch processing support</li></ul> |
| üõ°Ô∏è | **Security**      | <ul><li>No explicit security features; standard open-source practices</li></ul> |
| üì¶ | **Dependencies**  | <ul><li>Relies on `markdown`, `jupyternotebook`, `license` packages</li><li>Minimal external dependencies, primarily for documentation and notebooks</li></ul> |

---

## Project Structure

```sh
‚îî‚îÄ‚îÄ Building-A-Transformer-From-Scratch/
    ‚îú‚îÄ‚îÄ Attention Is All You Need.pdf
    ‚îú‚îÄ‚îÄ Decoder_Only_Transformer.ipynb
    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ Matrix Math Involved In A Transformer.pdf
    ‚îú‚îÄ‚îÄ README.md
    ‚îî‚îÄ‚îÄ Transformer Architecture.pdf
```

---

### Project Index

<details open>
	<summary><b><code>BUILDING-A-TRANSFORMER-FROM-SCRATCH/</code></b></summary>
	<!-- __root__ Submodule -->
	<details>
		<summary><b>__root__</b></summary>
		<blockquote>
			<div class='directory-path' style='padding: 8px 0; color: #666;'>
				<code><b>‚¶ø __root__</b></code>
			<table style='width: 100%; border-collapse: collapse;'>
			<thead>
				<tr style='background-color: #f8f9fa;'>
					<th style='width: 30%; text-align: left; padding: 8px;'>File Name</th>
					<th style='text-align: left; padding: 8px;'>Summary</th>
				</tr>
			</thead>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch/blob/master/Decoder_Only_Transformer.ipynb'>Decoder_Only_Transformer.ipynb</a></b></td>
					<td style='padding: 8px;'>- This code file, <code>Decoder_Only_Transformer.ipynb</code>, serves as an implementation and demonstration of a decoder-only transformer architecture within the broader machine learning project<br>- Its primary purpose is to showcase how a transformer model can be constructed and utilized for sequence modeling tasks, such as language modeling or text generation<br>- By focusing on the decoder component, the notebook illustrates how to process input sequences to generate coherent outputs, aligning with the overall architecture designed for efficient, autoregressive prediction<br>- It acts as both an educational resource and a functional prototype, integrating seamlessly into the project‚Äôs modular structure for developing advanced transformer-based models.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch/blob/master/LICENSE'>LICENSE</a></b></td>
					<td style='padding: 8px;'>- Provides the licensing terms for the project, establishing legal permissions and restrictions for software use, distribution, and modification within the overall architecture<br>- Ensures clarity on intellectual property rights, facilitating open-source collaboration and distribution while protecting the authors rights<br>- Serves as a foundational legal document supporting the projects open-source ecosystem.</td>
				</tr>
				<tr style='border-bottom: 1px solid #eee;'>
					<td style='padding: 8px;'><b><a href='https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch/blob/master/README.md'>README.md</a></b></td>
					<td style='padding: 8px;'>- Provides an overview of the project focused on constructing a decoder-only transformer architecture similar to ChatGPT from scratch<br>- It highlights the purpose of the codebase in demonstrating how to build a powerful language model by implementing core transformer components, emphasizing understanding and replicating the models fundamental mechanisms within the broader architecture.</td>
				</tr>
			</table>
		</blockquote>
	</details>
</details>

---

## Getting Started

### Prerequisites

This project requires the following dependencies:

- **Programming Language:** JupyterNotebook

### Installation

Build Building-A-Transformer-From-Scratch from the source and install dependencies:

1. **Clone the repository:**

    ```sh
    ‚ùØ git clone https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch
    ```

2. **Navigate to the project directory:**

    ```sh
    ‚ùØ cd Building-A-Transformer-From-Scratch
    ```
    
## Contributing

- **üí¨ [Join the Discussions](https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch/discussions)**: Share your insights, provide feedback, or ask questions.
- **üêõ [Report Issues](https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch/issues)**: Submit bugs found or log feature requests for the `Building-A-Transformer-From-Scratch` project.
- **üí° [Submit Pull Requests](https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch/blob/main/CONTRIBUTING.md)**: Review open PRs, and submit your own PRs.

<details closed>
<summary>Contributing Guidelines</summary>

1. **Fork the Repository**: Start by forking the project repository to your github account.
2. **Clone Locally**: Clone the forked repository to your local machine using a git client.
   ```sh
   git clone https://github.com/muhammadhussain-2009/Building-A-Transformer-From-Scratch
   ```
3. **Create a New Branch**: Always work on a new branch, giving it a descriptive name.
   ```sh
   git checkout -b new-feature-x
   ```
4. **Make Your Changes**: Develop and test your changes locally.
5. **Commit Your Changes**: Commit with a clear message describing your updates.
   ```sh
   git commit -m 'Implemented new feature x.'
   ```
6. **Push to github**: Push the changes to your forked repository.
   ```sh
   git push origin new-feature-x
   ```
7. **Submit a Pull Request**: Create a PR against the original project repository. Clearly describe the changes and their motivations.
8. **Review**: Once your PR is reviewed and approved, it will be merged into the main branch. Congratulations on your contribution!
</details>

<details closed>
<summary>Contributor Graph</summary>
<br>
<p align="left">
   <a href="https://github.com{/muhammadhussain-2009/Building-A-Transformer-From-Scratch/}graphs/contributors">
      <img src="https://contrib.rocks/image?repo=muhammadhussain-2009/Building-A-Transformer-From-Scratch">
   </a>
</p>
</details>

---

## License

Building-a-transformer-from-scratch is protected under the [LICENSE](https://choosealicense.com/licenses) License. For more details, refer to the [LICENSE](https://choosealicense.com/licenses/) file.

---

<div align="left"><a href="#top">‚¨Ü Return</a></div>

---
